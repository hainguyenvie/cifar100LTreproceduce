#!/usr/bin/env python3
"""
Compare and Summary Script
Compares the new comprehensive inference results with demo_inference results
"""

from pathlib import Path
import json

def compare_results():
    """Compare the outputs and provide summary."""
    
    print("üîç COMPARISON: Comprehensive vs Demo Inference")
    print("=" * 60)
    
    # Check demo_inference results
    demo_dir = Path('./inference_analysis_results')
    comprehensive_dir = Path('./comprehensive_inference_results')
    individual_dir = comprehensive_dir / 'individual_samples'
    
    print("üìä OUTPUT COMPARISON:")
    print("\nüéØ DEMO_INFERENCE.PY (Original):")
    if demo_dir.exists():
        demo_files = list(demo_dir.glob('*'))
        for file in sorted(demo_files):
            print(f"   ‚úÖ {file.name}")
        print(f"   Total files: {len(demo_files)}")
    else:
        print("   ‚ùå No demo inference results found")
    
    print("\nüöÄ COMPREHENSIVE_INFERENCE.PY (New Enhanced):")
    if comprehensive_dir.exists():
        # Main directory files
        main_files = [f for f in comprehensive_dir.glob('*') if f.is_file()]
        for file in sorted(main_files):
            print(f"   ‚úÖ {file.name}")
            
        # Individual samples directory
        if individual_dir.exists():
            individual_files = list(individual_dir.glob('*'))
            print(f"   ‚úÖ individual_samples/ ({len(individual_files)} files)")
            
            # Show some examples
            png_files = list(individual_dir.glob('*.png'))
            txt_files = list(individual_dir.glob('*_summary.txt'))
            print(f"     ‚Ä¢ {len(png_files)} visualization files (.png)")
            print(f"     ‚Ä¢ {len(txt_files)} text summary files (.txt)")
            print(f"     ‚Ä¢ 1 overall summary file")
            
        total_files = len(main_files) + len(list(individual_dir.glob('*'))) if individual_dir.exists() else len(main_files)
        print(f"   Total files: {total_files}")
    
    print("\nüìà FEATURE COMPARISON:")
    print("\n‚ú® MAINTAINED FEATURES (from demo_inference.py):")
    print("   ‚úÖ Individual sample visualization (4-panel charts)")
    print("   ‚úÖ Detailed text summaries with mathematical explanations")
    print("   ‚úÖ Expert posterior analysis")
    print("   ‚úÖ Gating weight analysis")
    print("   ‚úÖ Mixture distribution visualization")
    print("   ‚úÖ Decision process explanation")
    print("   ‚úÖ Step-by-step margin calculations")
    
    print("\nüöÄ NEW ENHANCED FEATURES:")
    print("   ‚úÖ 50 samples instead of 3 (30 Head + 20 Tail)")
    print("   ‚úÖ Stratified random sampling")
    print("   ‚úÖ Comprehensive statistical analysis")
    print("   ‚úÖ CSV export for further analysis")
    print("   ‚úÖ JSON export for raw data")
    print("   ‚úÖ Group-wise performance metrics")
    print("   ‚úÖ Decision quality analysis")
    print("   ‚úÖ Expert weight distribution analysis")
    print("   ‚úÖ Margin distribution analysis")
    print("   ‚úÖ Overall dashboard visualization")
    print("   ‚úÖ Sample highlights visualization")
    print("   ‚úÖ Intelligent sample selection for detailed analysis")
    
    print("\nüéØ KEY ADVANTAGES:")
    print("   1. SCALABILITY: 50 samples vs 3 samples")
    print("   2. STATISTICAL RIGOR: Proper stratified sampling")
    print("   3. COMPREHENSIVE ANALYSIS: Multiple visualization types")
    print("   4. DATA EXPORT: CSV/JSON for external analysis")
    print("   5. ORGANIZED OUTPUT: Structured folder hierarchy")
    print("   6. SELECTIVE DETAIL: Smart selection of interesting samples")
    print("   7. BOTH OVERVIEW AND DETAIL: Macro + micro analysis")
    
    # Check if we can load the comprehensive results
    results_file = comprehensive_dir / 'inference_results.json'
    if results_file.exists():
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        print(f"\nüìä COMPREHENSIVE RESULTS SUMMARY:")
        print(f"   ‚Ä¢ Total samples analyzed: {len(results)}")
        
        # Calculate some quick stats
        correct_count = sum(1 for r in results if r['is_correct'])
        accepted_count = sum(1 for r in results if r['is_accepted'])
        head_count = sum(1 for r in results if r['group_name'] == 'Head')
        tail_count = sum(1 for r in results if r['group_name'] == 'Tail')
        
        print(f"   ‚Ä¢ Prediction accuracy: {correct_count/len(results):.1%}")
        print(f"   ‚Ä¢ Acceptance rate: {accepted_count/len(results):.1%}")
        print(f"   ‚Ä¢ Head samples: {head_count}")
        print(f"   ‚Ä¢ Tail samples: {tail_count}")
        
        # Decision quality
        correct_accepts = sum(1 for r in results if r['is_accepted'] and r['is_correct'])
        correct_rejects = sum(1 for r in results if not r['is_accepted'] and not r['is_correct'])
        good_decisions = correct_accepts + correct_rejects
        
        print(f"   ‚Ä¢ Decision quality: {good_decisions/len(results):.1%}")
    
    print("\nüí° USE CASES:")
    print("   üìã DEMO_INFERENCE.PY: Best for...")
    print("     ‚Ä¢ Quick understanding of a few samples")
    print("     ‚Ä¢ Educational/demonstration purposes")
    print("     ‚Ä¢ Debugging specific samples")
    
    print("   üìä COMPREHENSIVE_INFERENCE.PY: Best for...")
    print("     ‚Ä¢ Research and evaluation")
    print("     ‚Ä¢ Statistical analysis")
    print("     ‚Ä¢ Model performance assessment")
    print("     ‚Ä¢ Publication-quality results")
    print("     ‚Ä¢ Comprehensive model understanding")
    
    print(f"\nüéâ SUCCESS: Enhanced inference system ready!")
    print(f"   Both approaches are available and complement each other.")

if __name__ == '__main__':
    compare_results()